{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Introduction to Data Analytics - Exercise set 5 - data processing and management</b></h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all your exercises (Jupyter Notebooks or Python-files) in your course Git-project.\n",
    "Use either code comments or Jupyter Notebook markdown (text) to document which exercise you are doing and what a certain code section does! \n",
    "You can return all of these exercises in a single Jupyter Notebook, if you wish."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color: red;\"><b>NOTE: The JSON/XML –files in Moodle in these exercises have been randomly generated. In other words, the data doesn't make any sense!</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can import numpy and pandas here etc.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import requests\n",
    "from pandas import json_normalize\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "file_path_coffee = 'coffee_sales.csv'\n",
    "df_coffee_sales = pd.read_csv(file_path_coffee)\n",
    "\n",
    "file_path_temperature_fixed = 'temperatures_fixed.csv'\n",
    "df_temperature_fixed = pd.read_csv(file_path_temperature_fixed)\n",
    "\n",
    "file_path_temperature_unfixed = 'temperatures_unfixed.csv'\n",
    "df_temperature_unfixed = pd.read_csv(file_path_temperature_unfixed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>1. </b>Download <b>\"simple.json\"</b> in Moodle, and load it in pandas.</b> </h4>\n",
    "<p>\n",
    "The DataFrame should look like this:\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex51.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>owned_by</th>\n",
       "      <th>acquired</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chrysler</td>\n",
       "      <td>Voyager</td>\n",
       "      <td>2001</td>\n",
       "      <td>Wolff-Trantow</td>\n",
       "      <td>28/12/2016</td>\n",
       "      <td>11565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Jetta</td>\n",
       "      <td>1995</td>\n",
       "      <td>Schuppe, Pfeffer and Klein</td>\n",
       "      <td>20/4/2016</td>\n",
       "      <td>52431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>Cayenne</td>\n",
       "      <td>2005</td>\n",
       "      <td>Mante Group</td>\n",
       "      <td>11/6/2020</td>\n",
       "      <td>75552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>928</td>\n",
       "      <td>1994</td>\n",
       "      <td>Wisozk Group</td>\n",
       "      <td>17/6/2019</td>\n",
       "      <td>30331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>SL-Class</td>\n",
       "      <td>2007</td>\n",
       "      <td>Schiller-Littel</td>\n",
       "      <td>20/7/2018</td>\n",
       "      <td>62385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          brand     model  year                    owned_by    acquired  \\\n",
       "0   1       Chrysler   Voyager  2001               Wolff-Trantow  28/12/2016   \n",
       "1   2     Volkswagen     Jetta  1995  Schuppe, Pfeffer and Klein   20/4/2016   \n",
       "2   3        Porsche   Cayenne  2005                 Mante Group   11/6/2020   \n",
       "3   4        Porsche       928  1994                Wisozk Group   17/6/2019   \n",
       "4   5  Mercedes-Benz  SL-Class  2007             Schiller-Littel   20/7/2018   \n",
       "\n",
       "   price  \n",
       "0  11565  \n",
       "1  52431  \n",
       "2  75552  \n",
       "3  30331  \n",
       "4  62385  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code here\n",
    "\n",
    "df_simple_json = pd.read_json('simple.json')\n",
    "df_simple_json.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>2.</b> Download <b>\"simple.xml\"</b> in Moodle, and load it in pandas</h4>\n",
    "<p>\n",
    "<span style=\"color: red\"><b>(Note:</b> if using pandas.read_xml(), use also the xpath-parameter!)</span><br /><br >The Series should look something like this:\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex52.png\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex52cars.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>owned_by</th>\n",
       "      <th>acquired</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oldsmobile</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2003</td>\n",
       "      <td>Herzog, Rodriguez and Howe</td>\n",
       "      <td>21/10/2016</td>\n",
       "      <td>32571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       brand   model  year                    owned_by    acquired  price\n",
       "0   1  Oldsmobile  Aurora  2003  Herzog, Rodriguez and Howe  21/10/2016  32571"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code here\n",
    "\n",
    "df_simple_xml = pd.read_xml('simple.xml', xpath=\"/*\")\n",
    "df_simple_xml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>3. Load this API-data into a pandas DataFrame:</b></h4>\n",
    "<p><a href=\"https://edu.frostbit.fi/api/events\">https://edu.frostbit.fi/api/events</a></p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Remember to use json_normalize to help you out with the categories and address information.<br /><b>Have address information in their own columns, and categories as separate rows.</b><br />The DataFrame should look something like this (note that the data changes daily, and exact values will vary):\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex53.png\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex53events.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>categories</th>\n",
       "      <th>address.street_address</th>\n",
       "      <th>address.postal_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taapero tiistai</td>\n",
       "      <td>14.5.2024</td>\n",
       "      <td>kuvataide</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taapero tiistai</td>\n",
       "      <td>14.5.2024</td>\n",
       "      <td>leikkiminen</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taapero tiistai</td>\n",
       "      <td>14.5.2024</td>\n",
       "      <td>osallistuminen</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Espoon kirjastojen Ympäristökevät</td>\n",
       "      <td>10.4.2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Siltakatu 11</td>\n",
       "      <td>02770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liikuntaleikit</td>\n",
       "      <td>27.5.2024</td>\n",
       "      <td>leikkiminen</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liikuntaleikit</td>\n",
       "      <td>27.5.2024</td>\n",
       "      <td>liikunta</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liikuntaleikit</td>\n",
       "      <td>27.5.2024</td>\n",
       "      <td>ulkoilu</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liikuntaleikit</td>\n",
       "      <td>27.5.2024</td>\n",
       "      <td>urheilu</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Musa-aamu</td>\n",
       "      <td>16.5.2024</td>\n",
       "      <td>leikkiminen</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Musa-aamu</td>\n",
       "      <td>16.5.2024</td>\n",
       "      <td>musiikki</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Etsintäpartio</td>\n",
       "      <td>10.4.2024</td>\n",
       "      <td>leikkiminen</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Etsintäpartio</td>\n",
       "      <td>10.4.2024</td>\n",
       "      <td>liikunta</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Etsintäpartio</td>\n",
       "      <td>10.4.2024</td>\n",
       "      <td>osallistuminen</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Etsintäpartio</td>\n",
       "      <td>10.4.2024</td>\n",
       "      <td>ulkoilu</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Etsintäpartio</td>\n",
       "      <td>10.4.2024</td>\n",
       "      <td>urheilu</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taaperoiden liikuntarata</td>\n",
       "      <td>12.4.2024</td>\n",
       "      <td>leikkiminen</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taaperoiden liikuntarata</td>\n",
       "      <td>12.4.2024</td>\n",
       "      <td>liikunta</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taaperoiden liikuntarata</td>\n",
       "      <td>12.4.2024</td>\n",
       "      <td>osallistuminen</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taaperoiden liikuntarata</td>\n",
       "      <td>12.4.2024</td>\n",
       "      <td>urheilu</td>\n",
       "      <td>Agnetankuja 4</td>\n",
       "      <td>00810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tapiolan Vapun avaus</td>\n",
       "      <td>30.4.2024</td>\n",
       "      <td>kirjastot</td>\n",
       "      <td>Tapiontori 1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tapiolan Vapun avaus</td>\n",
       "      <td>30.4.2024</td>\n",
       "      <td>kulttuuritapahtumat</td>\n",
       "      <td>Tapiontori 1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tapiolan Vapun avaus</td>\n",
       "      <td>30.4.2024</td>\n",
       "      <td>musiikki</td>\n",
       "      <td>Tapiontori 1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tapiolan Vapun avaus</td>\n",
       "      <td>30.4.2024</td>\n",
       "      <td>pohjois-tapiola</td>\n",
       "      <td>Tapiontori 1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tapiolan Vapun avaus</td>\n",
       "      <td>30.4.2024</td>\n",
       "      <td>tapiola</td>\n",
       "      <td>Tapiontori 1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Roskaton Helsinki -tapaaminen nuorille</td>\n",
       "      <td>20.4.2024</td>\n",
       "      <td>kuvataide</td>\n",
       "      <td>Klaneettitie 5</td>\n",
       "      <td>00420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Roskaton Helsinki -tapaaminen nuorille</td>\n",
       "      <td>20.4.2024</td>\n",
       "      <td>osallistuminen</td>\n",
       "      <td>Klaneettitie 5</td>\n",
       "      <td>00420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yhteislaulua Furahakörenin kanssa</td>\n",
       "      <td>29.4.2024</td>\n",
       "      <td>konsertit</td>\n",
       "      <td>Topeliuksenkatu 6</td>\n",
       "      <td>00250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yhteislaulua Furahakörenin kanssa</td>\n",
       "      <td>29.4.2024</td>\n",
       "      <td>musiikki</td>\n",
       "      <td>Topeliuksenkatu 6</td>\n",
       "      <td>00250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     name       date           categories  \\\n",
       "0                         Taapero tiistai  14.5.2024            kuvataide   \n",
       "0                         Taapero tiistai  14.5.2024          leikkiminen   \n",
       "0                         Taapero tiistai  14.5.2024       osallistuminen   \n",
       "1       Espoon kirjastojen Ympäristökevät  10.4.2024                  NaN   \n",
       "2                          Liikuntaleikit  27.5.2024          leikkiminen   \n",
       "2                          Liikuntaleikit  27.5.2024             liikunta   \n",
       "2                          Liikuntaleikit  27.5.2024              ulkoilu   \n",
       "2                          Liikuntaleikit  27.5.2024              urheilu   \n",
       "3                               Musa-aamu  16.5.2024          leikkiminen   \n",
       "3                               Musa-aamu  16.5.2024             musiikki   \n",
       "4                           Etsintäpartio  10.4.2024          leikkiminen   \n",
       "4                           Etsintäpartio  10.4.2024             liikunta   \n",
       "4                           Etsintäpartio  10.4.2024       osallistuminen   \n",
       "4                           Etsintäpartio  10.4.2024              ulkoilu   \n",
       "4                           Etsintäpartio  10.4.2024              urheilu   \n",
       "5                Taaperoiden liikuntarata  12.4.2024          leikkiminen   \n",
       "5                Taaperoiden liikuntarata  12.4.2024             liikunta   \n",
       "5                Taaperoiden liikuntarata  12.4.2024       osallistuminen   \n",
       "5                Taaperoiden liikuntarata  12.4.2024              urheilu   \n",
       "6                    Tapiolan Vapun avaus  30.4.2024            kirjastot   \n",
       "6                    Tapiolan Vapun avaus  30.4.2024  kulttuuritapahtumat   \n",
       "6                    Tapiolan Vapun avaus  30.4.2024             musiikki   \n",
       "6                    Tapiolan Vapun avaus  30.4.2024      pohjois-tapiola   \n",
       "6                    Tapiolan Vapun avaus  30.4.2024              tapiola   \n",
       "7  Roskaton Helsinki -tapaaminen nuorille  20.4.2024            kuvataide   \n",
       "7  Roskaton Helsinki -tapaaminen nuorille  20.4.2024       osallistuminen   \n",
       "8       Yhteislaulua Furahakörenin kanssa  29.4.2024            konsertit   \n",
       "8       Yhteislaulua Furahakörenin kanssa  29.4.2024             musiikki   \n",
       "\n",
       "  address.street_address address.postal_code  \n",
       "0          Agnetankuja 4               00810  \n",
       "0          Agnetankuja 4               00810  \n",
       "0          Agnetankuja 4               00810  \n",
       "1           Siltakatu 11               02770  \n",
       "2          Agnetankuja 4               00810  \n",
       "2          Agnetankuja 4               00810  \n",
       "2          Agnetankuja 4               00810  \n",
       "2          Agnetankuja 4               00810  \n",
       "3          Agnetankuja 4               00810  \n",
       "3          Agnetankuja 4               00810  \n",
       "4          Agnetankuja 4               00810  \n",
       "4          Agnetankuja 4               00810  \n",
       "4          Agnetankuja 4               00810  \n",
       "4          Agnetankuja 4               00810  \n",
       "4          Agnetankuja 4               00810  \n",
       "5          Agnetankuja 4               00810  \n",
       "5          Agnetankuja 4               00810  \n",
       "5          Agnetankuja 4               00810  \n",
       "5          Agnetankuja 4               00810  \n",
       "6           Tapiontori 1                None  \n",
       "6           Tapiontori 1                None  \n",
       "6           Tapiontori 1                None  \n",
       "6           Tapiontori 1                None  \n",
       "6           Tapiontori 1                None  \n",
       "7         Klaneettitie 5               00420  \n",
       "7         Klaneettitie 5               00420  \n",
       "8      Topeliuksenkatu 6               00250  \n",
       "8      Topeliuksenkatu 6               00250  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code here\n",
    "\n",
    "url = \"https://edu.frostbit.fi/api/events\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "df = json_normalize(data)\n",
    "df = df.explode('categories')\n",
    "\n",
    "if 'address' in df.columns:\n",
    "    address_columns = ['address.street_address', 'address.postal_code']\n",
    "    df[address_columns] = df['address'].apply(pd.Series)\n",
    "    df.drop(columns=['address'], inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>4. Use web scraping (e.g. BeautifulSoup), and use it to get the following info from the Rovaniemi Wikipedia –page</b></h4>\n",
    "<p><b>Wiki-page:</b> <a href=\"https://en.wikipedia.org/wiki/Rovaniemi\">https://en.wikipedia.org/wiki/Rovaniemi</a></p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tasks:</b>\n",
    "<ul>\n",
    "    <li>Get the coordinates of Rovaniemi (upper right corner)</li>\n",
    "    <li>Get the nickname of Rovaniemi (under coat of arms)</li>\n",
    "</ul>\n",
    "\n",
    "<b>Advanced extra tasks:</b>\n",
    "<ul>\n",
    "    <li><b>Get the total population</b></li>\n",
    "    <ul>\n",
    "        <li><b>Note:</b> this is a good example why webscraping can be tedious, since you'll have to traverse the HTML-tree to get what you want. This might be helpful:<br />\n",
    "<a href=\"https://realpython.com/beautiful-soup-web-scraper-python/\">https://realpython.com/beautiful-soup-web-scraper-python/</a></li>\n",
    "    </ul>\n",
    "    \n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "    <li><b>Get the total area</b></li>\n",
    "    <ul>\n",
    "        <li>Convert this number into a float decimal (i.e. remove commas and the unit and call float() –in Python!)</li>\n",
    "    </ul>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex54rovaniemi.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates of Rovaniemi: 66.500°N 25.733°E\n",
      "Nickname of Rovaniemi: Arctic Capital; Hometown of Santa Claus\n"
     ]
    }
   ],
   "source": [
    "# code here\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Rovaniemi\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# The coordinates of Rovaniemi (upper right corner)\n",
    "coordinates = soup.find(\"span\", class_=\"geo-dec\").text.strip()\n",
    "print(\"Coordinates of Rovaniemi:\", coordinates)\n",
    "\n",
    "# The nickname of Rovaniemi\n",
    "nickname_div = soup.find(\"div\", class_=\"ib-settlement-nickname\")\n",
    "nickname = nickname_div.text.strip() if nickname_div else \"Nickname not found\"\n",
    "print(\"Nickname of Rovaniemi:\", nickname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>5. Use web scraping, and create a DataFrame of this table: </b></h4>\n",
    "<p> <a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_average_yearly_temperature\">https://en.wikipedia.org/wiki/List_of_countries_by_average_yearly_temperature</a></p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Change the name of the value column to \"avg_temp\" as well (pandas column rename)</li>\n",
    "</ul>\n",
    "\n",
    "<b>Advanced extra task:</b>\n",
    "<ul>\n",
    "    <li><b>Scrape these two tables as well</b></li>\n",
    "    <ul>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_employment_rate\">https://en.wikipedia.org/wiki/List_of_countries_by_employment_rate</a></li>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_unemployment_rate\">https://en.wikipedia.org/wiki/List_of_countries_by_unemployment_rate</a></li>\n",
    "    </ul>\n",
    "    <br />\n",
    "    <ul>\n",
    "        <li><b>Combine the tables into a single DataFrame so that you get only the data of year 2020 or newer, and have the columns <span style=\"color: darkorange\">\"Country\", \"EmploymentRate\"</span> and <span style=\"color: darkorange\">\"UnemploymentRate\"</span>. You can also create additional columns <span style=\"color: red\">\"EmploymentRate15_24\"</span>and <span style=\"color: red\">\" EmploymentRate25_70\"</span> if you scrape the OECD-table as well! </b>\n",
    "\n",
    "</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex55stocks.jpg\" width=\"450\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Country             avg_temp\n",
      "0  Burkina Faso  28.29 °C (82.92 °F)\n",
      "1          Mali  28.25 °C (82.85 °F)\n",
      "2      Kiribati  28.20 °C (82.76 °F)\n",
      "3      Djibouti  28.00 °C (82.40 °F)\n",
      "4      Maldives  28.00 °C (82.40 °F)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l9/x0255jx977jgl0hnb9tcnzr80000gp/T/ipykernel_92538/3592398202.py:10: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  temperature = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_countries_by_average_yearly_temperature\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\", class_=\"wikitable\")\n",
    "\n",
    "temperature = pd.read_html(str(table))[0]\n",
    "\n",
    "temperature.rename(columns={\"Temperature (°C)\": \"avg_temp\"}, inplace=True)\n",
    "\n",
    "print(temperature.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>6. Simple merging:</b> Download <u><b>coffee_sales.csv</b></u> and <b><u>temperatures_fixed.csv</u></b> from Moodle.<b></h4>\n",
    "<p>Use merging to combine these files into one DataFrame, containing the coffee sales data and the corresponding temperature –data. (merge(), see materials for examples)</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\"><b>Use left join, and coffee sales as the first DataFrame!</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Sales  Target_sales  Total_expenses  Temperature (C)\n",
      "0  1.10.2012    122            90              76        19.822917\n",
      "1  1.10.2012    123            90              45        19.822917\n",
      "2  2.10.2012    107            90              36        19.020602\n",
      "3  3.10.2012     94           100              21        15.820139\n",
      "4  4.10.2012    182            80              54        15.110648\n"
     ]
    }
   ],
   "source": [
    "# code here\n",
    "\n",
    "merged_df = pd.merge(df_coffee_sales, df_temperature_fixed, on=\"Date\", how=\"left\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Extra task: </b> Do the same but with <b>temperatures_unfixed.csv</b> instead. Remember <b>groupby()</b> before attempting merging! \n",
    "\n",
    "<b>Also, you might want to remove some of the columns before grouping data => <span style=\"color: red;\">Summary + Hour</span>. </b>\n",
    "\n",
    "<span><i>You can also try to merge the DataFrames so that the Summary –of the weather is also added. For this, you probably need to figure out first how to determine the \"average\" Summary for each day (extra challenge!).</i></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Sales  Target_sales  Total_expenses  Temperature (C)\n",
      "0  1.10.2012    122            90              76        19.822917\n",
      "1  1.10.2012    123            90              45        19.822917\n",
      "2  2.10.2012    107            90              36        19.020602\n",
      "3  3.10.2012     94           100              21        15.820139\n",
      "4  4.10.2012    182            80              54        15.110648\n"
     ]
    }
   ],
   "source": [
    "# extra task code here, if done\n",
    "\n",
    "df_temperature_unfixed.drop(columns=[\"Summary\", \"Hour\"], inplace=True)\n",
    "\n",
    "average_temp = df_temperature_unfixed.groupby(\"Date\").mean().reset_index()\n",
    "merged_df = pd.merge(df_coffee_sales, average_temp, on=\"Date\", how=\"left\")\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex56coffee.jpg\" width=\"450\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2><b>Advanced extra tasks for extra points (varying challenges, some require Googling):</b></h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>1. Download the \"complex.json\" –file from Moodle.</b> Note that this data is fairly complex (i.e. heavily nested). Use json_normalize and other needed methods to convert this data into a workable DataFrame.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id      brand          model  year  price                     company  \\\n",
      "0   1       Ford           F250  1997  72213              Johns and Sons   \n",
      "1   2      Dodge  Grand Caravan  1999  42370    Crist, Hyatt and Leannon   \n",
      "2   3       Audi             A5  2011  19191              Bosco and Sons   \n",
      "3   4    Hyundai       Veracruz  2012  21956                   Haley Inc   \n",
      "4   5  Chevrolet    TrailBlazer  2009  53066  Zulauf, Nolan and Franecki   \n",
      "\n",
      "     acquired payment (credit card)                      payment (iban)  \n",
      "0  24/10/2017                   jcb       SA47 315V KYTA 8FVT NCGN MM7G  \n",
      "1    7/6/2020          instapayment   FR74 8157 1767 53I2 VRAN ZMIB U11  \n",
      "2  23/11/2018                   jcb  LB32 4989 VCVZ S5BZ X2CT JKG3 QRAW  \n",
      "3    5/6/2016              bankcard                 BE62 4961 0596 5774  \n",
      "4   14/1/2021                   jcb   FR11 1768 5506 10IU QVPN XU2H O88  \n"
     ]
    }
   ],
   "source": [
    "# code for the advanced extra task\n",
    "\n",
    "with open(\"complex.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "df = pd.json_normalize(data)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df.rename(columns={\"ownership.company\": \"company\"}, inplace=True)\n",
    "df.rename(columns={\"ownership.acquired\": \"acquired\"}, inplace=True)\n",
    "df.rename(columns={\"ownership.payment_info.credit_card\": \"payment (credit card)\"}, inplace=True)\n",
    "df.rename(columns={\"ownership.payment_info.iban\": \"payment (iban)\"}, inplace=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>2. Load the \"simple.json\" –file without pandas, and try to get the average price with plain Python. </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average price: 42373.86\n"
     ]
    }
   ],
   "source": [
    "# code for the advanced extra task\n",
    "\n",
    "with open(\"simple.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "prices = [item[\"price\"] for item in data]\n",
    "average_price = sum(prices) / len(prices)\n",
    "\n",
    "print(\"Average price:\", average_price)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>3. Download the \"complex.xml\" file from Moodle, and create a DataFrame out of it.</b></li>\n",
    "<ul>\n",
    "    <li><b>Note:</b> using pandas.read_xml() would otherwise work, but it ignores the \"ownership\" –field. You'll have to find another way to get this data into your DataFrame as well!</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task, you can also create a separate notebook for this \n",
    "# (might be a better idea, since a new dataset always adds quite much new code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>4. Try out Selenium on a site that cannot be scraped with traditional methods. You can use this tutorial as the starting point:</b></li>\n",
    "    <ul>\n",
    "        <li><a href=\"https://www.toptal.com/python/web-scraping-with-python\">https://www.toptal.com/python/web-scraping-with-python</a></li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task, you can also create a separate notebook for this \n",
    "# (might be a better idea, since a new dataset always adds quite much new code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex5charts.jpg\" width=\"600\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. Extra challenging advanced task: <span style=\"color: red;\">integrating data sources</span></b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>Integrate two or more datasets into one matching dataset  (pandas DataFrame), but use any datasets you can find in Kaggle instead of the previous coffee sales + temperature -datasets</b></li>\n",
    "<br />\n",
    "<ul>\n",
    "<li>Find two or more datasets (Kaggle etc.) that have something in common and can be used for merging. </li>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>Typical common columns:</b></li>\n",
    "<ul>\n",
    "<li>Coordinates (lat/lng etc.)</li>\n",
    "<li>Years, months</li>\n",
    "<li>reference ids (e.g. product id -> product data)</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>You can use pandas.merge() in order to combine DataFrames</b></li>\n",
    "<ul>\n",
    "<li>When combining DataFrames, make sure that the merge doesn’t mess up your data</li>\n",
    "<li><b>Note:</b> merge can often create way too many extra rows depending on the merging parameters</li>\n",
    "\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>This exercise can provide even large amounts of points, depending on difficulty. Aspects that affect grading:</b></li>\n",
    "<ul>\n",
    "<li>Amount of datasets</li>\n",
    "<li>Difficulty of the datasets</li>\n",
    "<li>Using different data formats all at once (XML, JSON, CSV etc.)</li>\n",
    "<li>Other techniques used to add data: web scraping, data APIs etc.</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this exercise is probably better to do in a separate Jupyter notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b393597a1a01400f99fd0b0bd7e53e32f7c09a6c4e3f1d7dcfe73f5e3a50c61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
